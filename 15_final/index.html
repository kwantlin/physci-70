<!DOCTYPE html>
<html lang="en">
<head>
  <title>PHYSCI 70: Intro to Digital Fabrication </title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <link href="../style.css" rel="stylesheet">
</head>
<body>
  <div class="header">
    <a href="../index.html" class="logo underline--magical">Home</a>
    <div class="header-right">
      <a class="underline--magical" href="../about/index.html">About</a>
    </div>
  </div>
<div class="container-fluid">
  <h3 class="heading1">Final Project Process Page</h3> <br> 
  <div class="row content-2">
  April 13, 2021:

  This week, I focused on getting Unity ML Agents up and running. I followed this 
  <span class="underline--magical" onclick="location.href='https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Installation.md#install-the-comunityml-agents-unity-package';" style="cursor: pointer" >
    installation documentation
   </span>
   on the software's GitHub repository, installing Unity Hub, Unity, and the ML-Agents library. 
   <br><br>

   However, upon attempting to load the 3D Ball example
   mentioned in this 
   <span class="underline--magical" onclick="location.href='https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Getting-Started.md';" style="cursor: pointer" >
    beginner tutorial 
   </span>
   I received a multitude of compiler warnings. 
   
   <br><br>

   <img src="./unity-compile-warnings.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

   <br><br>

   Currently, I am attempting to work through those, and I believe it is because I was not using the same version of ML-Agents
   between the package repository and the Unity Package Manager. These files are all very large, so installation takes a while, but I will update further once this issue is resolved 
   and I can play the example simulation!
   <br><br>

   April 20, 2021:
   <br><br>

   After coming across
   <span class="underline--magical" onclick="location.href='https://forum.unity.com/threads/unity-does-not-recognise-mlagents-namespace.947286/';" style="cursor: pointer" >
    this discussion thread
   </span>
   I realized my error was due to the fact that I needed the ml-agent git repo and it's associated package.json files, which had to be added in Unity under packages manually.
   <br><br>

   The result, after removing the Tests folder, is that I can now run sample environments without issue!
   <br><br>

   <iframe src="https://giphy.com/embed/OtHHRXDHPOuZo9Mw57" style="align-content:centerd; display: block;margin-left: auto; margin-right: auto;" width="480" height="296" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/OtHHRXDHPOuZo9Mw57">via GIPHY</a></p>
    
   <br><br>
   My next step will be to get this 
   <span class="underline--magical" onclick="location.href='https://github.com/Ashwanikumarkashyap/air-hockey-with-unity-ml-agents-reinforcement-learning';" style="cursor: pointer" >
    GitHub repo
   </span>
   up and running, although I will need to replace the objects most likely. For exapmle, I will likely be using a ball rather than a puck since I likely won't have a super 
   slick surface to work with. I will also need to considerthe real world effects of friction as well as the force/speed that I can achieve with the stepper motor carriages.
   If necessary, I might need to change to an xy-plotter design for more fluid motion, although I will need to weigh down the "hockey sticks" somehow.
  
   April 27, 2021:
   <br><br>
   
   This week, I identified the major pieces of my project moving forward to create a comprehensive plan of action for my air hockey project. Here are the main points:
   <br><br>

   First, puck position sensing. After discussing several options with Nathan, I decided that the easiest method to detect the puck's position and respond to it would be through 
   using a camera and image-matting with OpenCV. This would give faster results than capacitive sensing alternatives. The issue for me is that the ESP32-CAM is not working, so I needed to see 
   if I could get images from my ArduCAM with my available boards. This is the issue I focused on debugging this week.
   <br><br>

   Second, the "hockey stick" using a linear carriage. I will need to connect two linear carriages in order to achieve xy-positioning to respond to the puck. To conserve materials, I will only make one automated 
   "player" and I will serve as the human opponent. If there is too much friction still with this setup, as experienced by some of my classmates, I may default to experimenting with 
   <span class="underline--magical" onclick="location.href='https://kem406.github.io/hbot/';" style="cursor: pointer" >
    xy-plotter design
   </span>
   A lot of experimentation will be necessary to see what maximum velocity I can achieve as well as how quickly the pipeline can respond to changes in puck positioning. 
   <br><br>

   This week, I will attempt to unify these pieces into a simple design - having the automated player detect the puck position and move in-line with it to block it from hitting the 
   opposite wall of the setup. With sufficient time, I will replace this with an RL trained model to determine commands.
   <br><br>

   My bill of materials is as follows:
   <br><br>
   1. 2 x lasercut linear carriage wood piece sets, Stepper Motor, timing belt, timing belt clip, 4 bearings, 12 M3x8 screws for steppers, 12 M5x0.8x16 screws for bearings, 12 M5 washers, 12 M3 washers
   <br>
   2. 1 Arduino ArduCAM + 8 M-F Wires
   <br>
   3. 1 Adafruit Metro MO board
   <br>
   4. 1 Arduino Nano 33 BLE Sense
   <br>
   5. 1 Puck / balls
   <br>
   6. 1 White Dry-erase board (slick surface for puck)

   <br>

   <br><br>

   This week I focused on getting the ArduCAM up and running with a board. 
   <br><br>

   Firstly, I attempted to connect it to the Metro using this pin connection scheme:
   <br><br>

   <img src="./arducam_pin.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">
   <br><br>

   I installed the necessary libraries using this 
   <span class="underline--magical" onclick="location.href='https://github.com/ArduCAM/Arduino';" style="cursor: pointer" >
   GitHub repo
   </span>
   <br><br>

   I was getting some issues running the setup lines, which verified proper pin connections, etc. I used the following code to ensure that i2c communication was working, as per this 
   <span class="underline--magical" onclick="location.href='https://github.com/ArduCAM/Arduino/issues/224';" style="cursor: pointer" >
    discussion thread's suggestion.
   </span>
   <br><br>

   <pre><code class="language-arduino">
    #include <Wire.h>


      void setup()
      {
        Wire.begin();
      
        Serial.begin(9600);
        Serial.println("\nI2C Scanner");
      }
      
      
      void loop()
      {
        byte error, address;
        int nDevices;
      
        Serial.println("Scanning...");
      
        nDevices = 0;
        for(address = 1; address < 127; address++ ) 
        {
          // The i2c_scanner uses the return value of
          // the Write.endTransmisstion to see if
          // a device did acknowledge to the address.
          Wire.beginTransmission(address);
          error = Wire.endTransmission();
      
          if (error == 0)
          {
            Serial.print("I2C device found at address 0x");
            if (address<16) 
              Serial.print("0");
            Serial.print(address,HEX);
            Serial.println("  !");
      
            nDevices++;
          }
          else if (error==4) 
          {
            Serial.print("Unknow error at address 0x");
            if (address<16) 
              Serial.print("0");
            Serial.println(address,HEX);
          }    
        }
        if (nDevices == 0)
          Serial.println("No I2C devices found\n");
        else
          Serial.println("done\n");
      
        delay(5000);           // wait 5 seconds for next scan
      }
  </code></pre>
  <br><br>

   This was working, but after some additional error, I realized the SPI connection was failing using the digital pins since I needed to use the Metro's SCK, MISO, and MOSI-specific pins.
   However, the example sketches that came with the library were still failing upon attempting to send information between camera and board, and after doing some research,
   I realized that the camera worked best with the tested Arduino Uno board, and would also work with the Arduino Nano BLE Sense that I had, but not an Adafruit board.
   Here's what the final setup looked like after doing the replacement:
   <br><br>

   <img src="./arducam.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">
   <br><br>


   After reloading the 2D capture example from the ArduCAM library, with the camera now hooked up to the Nano, I successfully got image capture! Although this example, wanted me to save the result to an SD card connected on 
   Pin 9, I was able to get successful capture and can use the remaining lines to transfer the image bytes from the buffer array to some other display. 
   The ArduCAM has a built in host system for viewing these images, but from my research and this
   <span class="underline--magical" onclick="location.href='https://github.com/ArduCAM/Arduino/issues/210';" style="cursor: pointer" >
    discussion thread
   </span>
   it seems that it only works on Windows. However, I've worked with this camera before to successfully capture and classify images with TFlite, so I think with some 
   work on transferring the data between devices, I should be able to visualize and latter apply an OpenCV filter for a certain colors down the line. 
   The code for image capture is below:
   <br><br>

   <pre><code class="language-arduino">
    #include <Wire.h>
    #include <ArduCAM.h>
    #include <SPI.h>
    #include <SD.h>
    #include "memorysaver.h"
    //This demo can only work on OV5640_MINI_5MP_PLUS or OV5642_MINI_5MP_PLUS platform.
    #if !(defined (OV5640_MINI_5MP_PLUS)||defined (OV5642_MINI_5MP_PLUS))
    #error Please select the hardware platform and camera module in the ../libraries/ArduCAM/memorysaver.h file
    #endif
    #define   FRAMES_NUM    0x06
    // set pin 7 as the slave select for the digital pot:
    const int CS = 7;
    //#define SD_CS 9
    bool is_header = false;
    int total_time = 0;
    #if defined (OV5640_MINI_5MP_PLUS)
      ArduCAM myCAM(OV5640, CS);
    #else
      ArduCAM myCAM(OV5642, CS);
    #endif
    uint8_t read_fifo_burst(ArduCAM myCAM);
    void setup() {
    // put your setup code here, to run once:
    uint8_t vid, pid;
    uint8_t temp;
    #if defined(__SAM3X8E__)
      Wire1.begin();
    #else
      Wire.begin();
    #endif
    Serial.begin(115200);
    Serial.println(F("ArduCAM Start!"));

    // set the CS as an output:
    pinMode(CS, OUTPUT);
    digitalWrite(CS, HIGH);

    // initialize SPI:
    SPI.begin();
    //Reset the CPLD
    myCAM.write_reg(0x07, 0x80);
    delay(100);
    myCAM.write_reg(0x07, 0x00);
    delay(100); 
      
    while(1){
      //Check if the ArduCAM SPI bus is OK
      myCAM.write_reg(ARDUCHIP_TEST1, 0x55);
      temp = myCAM.read_reg(ARDUCHIP_TEST1);
      if(temp != 0x55)
      {
        Serial.println(F("SPI interface Error!"));
        delay(1000);continue;
      }else{
        Serial.println(F("SPI interface OK."));break;
      }
    }
    #if defined (OV5640_MINI_5MP_PLUS)
    while(1){
      //Check if the camera module type is OV5640
      myCAM.rdSensorReg16_8(OV5640_CHIPID_HIGH, &vid);
      myCAM.rdSensorReg16_8(OV5640_CHIPID_LOW, &pid);
      if ((vid != 0x56) || (pid != 0x40)){
        Serial.println(F("Can't find OV5640 module!"));
        delay(1000); continue;
      }else{
        Serial.println(F("OV5640 detected."));break;      
      }
    }
    #else
    while(1){
      //Check if the camera module type is OV5642
      myCAM.rdSensorReg16_8(OV5642_CHIPID_HIGH, &vid);
      myCAM.rdSensorReg16_8(OV5642_CHIPID_LOW, &pid);
      if ((vid != 0x56) || (pid != 0x42)){
        Serial.println(F("Can't find OV5642 module!"));
        delay(1000);continue;
      }else{
        Serial.println(F("OV5642 detected."));break;      
      }
    }
    #endif
    //Initialize SD Card
    //while(!SD.begin(SD_CS))
    //{
    //  Serial.println(F("SD Card Error!"));delay(1000);
    //}
    //Serial.println(F("SD Card detected."));
    //Change to JPEG capture mode and initialize the OV5640 module
    myCAM.set_format(JPEG);
    myCAM.InitCAM();
    myCAM.set_bit(ARDUCHIP_TIM, VSYNC_LEVEL_MASK);
    myCAM.clear_fifo_flag();
    myCAM.write_reg(ARDUCHIP_FRAMES, FRAMES_NUM);
    }

    void loop() {
    // put your main code here, to run repeatedly:
    myCAM.flush_fifo();
    myCAM.clear_fifo_flag();
    #if defined (OV5640_MINI_5MP_PLUS)
      myCAM.OV5640_set_JPEG_size(OV5640_320x240);delay(1000);
    #else
      myCAM.OV5642_set_JPEG_size(OV5642_320x240);delay(1000);
    #endif
    //Start capture
    myCAM.start_capture();
    Serial.println(F("start capture."));
    total_time = millis();
    while ( !myCAM.get_bit(ARDUCHIP_TRIG, CAP_DONE_MASK)); 
    Serial.println(F("CAM Capture Done."));
    total_time = millis() - total_time;
    Serial.print(F("capture total_time used (in miliseconds):"));
    Serial.println(total_time, DEC);
    total_time = millis();
    read_fifo_burst(myCAM);
    total_time = millis() - total_time;
    Serial.print(F("save capture total_time used (in miliseconds):"));
    Serial.println(total_time, DEC);
    //Clear the capture done flag
    myCAM.clear_fifo_flag();
    delay(5000);
    }
    uint8_t read_fifo_burst(ArduCAM myCAM)
    {
    uint8_t temp = 0, temp_last = 0;
    uint32_t length = 0;
    static int i = 0;
    static int k = 0;
    char str[8];
    File outFile;
    byte buf[256]; 
    length = myCAM.read_fifo_length();
    Serial.print(F("The fifo length is :"));
    Serial.println(length, DEC);
    if (length >= MAX_FIFO_SIZE) //8M
    {
      Serial.println("Over size.");
      return 0;
    }
    if (length == 0 ) //0 kb
    {
      Serial.println(F("Size is 0."));
      return 0;
    } 
  </code></pre>
  <br><br>

  Here are the stats from the capture:

  <img src="./capture_result.png" style="height:200px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  It seems that capture takes around 7 seconds, which is definitely not great. I will need to see if this can be improved or if I will need to embed an accelerometer on the puck or use a different camera (IPhone camera?) to get the data I need. 
   <br><br>

  ---------------------------------------
  <br><br>
  May 13, 2021:
  <br><br>
  As my project stages coalesced, I saw the process come together as a series of constrained problems. The reason for this is that I (a) did not begin with a completely developed prototype plan and (b) ran into several unexpected setbacks. 
  However, the situation lent itself well to creative prototyping and I found myself actively recalling what I learned particularly in the kinetic sculpture and Bluetooth communication weeks.
  <br><br>
  For ease of reading, the rest of the documentation will follow the repeated outline of: goal, constraints, solution, steps, resource summary. Rather than linking the resources in the text, since there are so many, I'll summarize and link them all at the bottom of the relevant section. 
  <br><br>
  Stage #1: Vision-Enabled Gameplay
  <br><br>
  Goal: Get visual input to one of my boards to facilitate motor commands that align the striker with the puck accurately and quickly. From my research of similar implementations of this project, CV is the standard for puck position detection, as alternatives are slower or give less reliable data.
  <br><br>
  Constraints: 
  <br><br>
  1. No ESP32 boards function with my version of macOS due to a recent change in how apple handles kernel extensions, of which SiLabs' USB to UART driver is one. This prevents me from connecting to the port where the board is located and using boards handily equipped 
  with key WIFI and BLE communication protocols. My remaining options are Serial communication or to find some other board.
  <br><br>
  2. I only own enough IR Transistors and IR LEDs to create one (unreliable) depth sensor. Similarly, after discussiong alternatives to the CV solution with course staff, it seems like vision will definitely give the strongest results and should be the ideal to shoot for.
  <br><br>
  3. Since my hardward setup could change a lot, a low-calibration solution would be ideal.
  <br><br>
  Solution: Realizing I had an Arduino Nano 33 BLE Sense from a previous Harvard course (CS249: TinyML). Coupled with the ArduinoBLE library, I could 
  <br><br>
  Stage 1(a): Understand the ArduinoBLE library and how central/peripheral communication happens.


  <br><br>
  Stage 1(b): Get a Swift vision app working.
  <br><br>
  Stage 1(c): Combine the two previous sub-stages into one app that is a custom BLE central advertising to my Arduino peripheral. 
  <br><br>
  Stage 1(d): Migrate to version of BLE central creation in Swift that enables more flexibility in creating services and characteristics. 
  <br><br>
  Resources:
  <br><br>

  Stage 2: Assembling the playing field and strikers. 
  <br><br>
  Goal: Maximize speed that the strikers can achieve in x-y directions and minimize additional material purchases.
  <br><br>
  Constraints: 
  <br><br>
  1. At the beginning of the project process, not knowing exactly what I would need but having an inkling that linear stages would be involved, I asked course staff for materials to create 3 additional linear stages. 
  <br><br>
  2. The stepper motors we have work with 9V battery, so this power cap will limit the speed I can achieve.
  <br><br>
  For the above reasons, I would be battling friction and the weight limits that the motor can handle, especially since I want to set things up in an x-y plotter configuration. Stage 1 of the project also ended up consuming a lot of time and resources, even more so if I had not already 
  had the Nano board from a previous class. I experimented with household items like curtain rods and other metal/plastic alternatives, but due to a lack of sufficient brackets to secure things and a desire to get to a working prototype, I chose to stick with the wood. However, compared to when 
  I first worked with these stages, I knew a few tricks to reduce the resistance and maintain structural integrity.
  <br><br>
  Stage 2(a): Selecting an optimal size for the stages.
  <img src="./start-assemble-stages.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  <img src="./stages-assembled-together.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  <br><br>
  Stage 2(b): Getting the details right.
  <img src="./assembled-striker.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">
  <img src="./striker-on-stage.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  <img src="./final-assembly.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">
  <img src="./green-red-coding.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  <br><br>
  Stage 2(c): Optimizing stepper motor speed and acceleration.
  <br><br>
  Resources:
  <br><br>

  Stage 3: Dealing with Disaster
  <br><br>
  Unexpected Constraints:
  <br><br>
  1. The day before this project was due, I was busily making final adjustments to the programming, color-masking, BLE protocols, etc. in preparation for getting everything right for video filming. Alas, these last minute changes ended up spanning several hours (I tend to work in long sprints). Around the early evening, 
  as I went to upload new BLE code, I discovered that my Nano was no longer connected to my laptop and was quite hot. Thinking this was a board package issue, I updated and discovered that the Arduino MBED boards had indeed had their old package deprecated. However, even after installing the new Nano-specific package and even doing 
  a full reinstall of the Arduino IDE, my board would not connect. A little while later, the overheating had reached scalding levels, even with only a few minutes of connection and eventually even the LED that lights up on power connection went dark. This board was fried. 
  <br><br>
  <img src="./fried-nano.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">
  <br><br>

  Seeing as how this was the day before things were due and I had not done filming of the functioning BLE protocols since I needed to source a different phone to take video of my phone sending the data and also since I wanted to some simultaneous screen recordings. This was truly regrettable since so much of my time had been spent getting this working with minimal lag and making it look visually neat.
  <br><br>
  Goal: Showcase as much of the BLE work I did even if I couldn't demo it and somehow get video of functioning hardware ASAP for demo showcasing.
  <br><br>
  Solution: Since I had both halves of the process fleshed out and the only missing piece was a functioning BLE-enabled board, I decided instead of trying to debug a serial-based solution in a short time for the video demo, I would instead close the loop on both halves and demonstrate completion and replicability for anyone who has the hardware to connect them.
  <br><br>
  Stage 3(a): Gesture-controlled striker movement.
  <img src="./overhead-wiring.png" style="height:700px; width:auto; object-fit: cover; align-content:centerd; display: block;margin-left: auto; margin-right: auto;" class="img-responsive margin"  alt="Sim circuit">

  <br><br>
  Stage 3(b): Wrap up BLE side for easy replicability with functioning hardware.
  <br><br>

  Final Demo Video:
  <iframe width="760" height="515" src="https://www.youtube-nocookie.com/embed/73amvXIi6y4" style="align-content:centerd; display: block;margin-left: auto; margin-right: auto;" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

  <br><br>
  Takeaways:
  <br><br>
  1. I really like Swift development! Something about the way the storyboards and code connect and the pieces necessary to communicate between code in various languages was very unique. 
  <br><br>
  2. Extending the BLE communication we learned in class to develop my own protocol and essentially replicate the BLE centrals we took for granted was a very informative and rewarding process, especially when you can see the accurate data streaming to your Arduino.
  <br><br>
  3. 
  <br><br>

</div>
</div>

</body>
</html>